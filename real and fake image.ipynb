{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5d26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c607f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = r'C:\\Users\\itars\\M Pr\\archive\\real_vs_fake\\real-vs-fake\\train'\n",
    "valid = r'C:\\Users\\itars\\M Pr\\archive\\real_vs_fake\\real-vs-fake\\valid'\n",
    "test = r'C:\\Users\\itars\\M Pr\\archive\\real_vs_fake\\real-vs-fake\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e133b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "batch_size = 64\n",
    "train_flow = image_gen.flow_from_directory(\n",
    "    training,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "valid_flow = image_gen.flow_from_directory(\n",
    "    valid,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3a3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b4b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[224, 224, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e76c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8c6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8626a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7757b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f79ff0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf54c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8993cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "200de493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 93312)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11944064  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,987,361\n",
      "Trainable params: 11,987,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c9cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(\n",
    "        learning_rate=0.0001,\n",
    "        momentum=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e4b8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = opt , loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88fe7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.h5', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f7b6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b70c3786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itars\\AppData\\Local\\Temp\\ipykernel_12588\\449151198.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = cnn.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 15s 2s/step - loss: 0.0132 - accuracy: 0.9948\n"
     ]
    }
   ],
   "source": [
    "train_steps = 400//batch_size\n",
    "valid_steps = 50//batch_size\n",
    "history = cnn.fit_generator(\n",
    "    train_flow,\n",
    "    epochs=1,\n",
    "    steps_per_epoch = train_steps,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = valid_steps,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31e8ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6caad709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itars\\AppData\\Local\\Temp\\ipykernel_20868\\2188059181.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = cnn.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "625/625 [==============================] - 1459s 2s/step - loss: 0.2362 - accuracy: 0.9057 - val_loss: 0.2244 - val_accuracy: 0.9125\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 1404s 2s/step - loss: 0.1878 - accuracy: 0.9269 - val_loss: 0.2245 - val_accuracy: 0.9052\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 1322s 2s/step - loss: 0.1525 - accuracy: 0.9430 - val_loss: 0.1776 - val_accuracy: 0.9291\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 1348s 2s/step - loss: 0.1229 - accuracy: 0.9543 - val_loss: 0.1821 - val_accuracy: 0.9275\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 1369s 2s/step - loss: 0.1018 - accuracy: 0.9635 - val_loss: 0.1873 - val_accuracy: 0.9273\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 1344s 2s/step - loss: 0.0769 - accuracy: 0.9725 - val_loss: 0.1448 - val_accuracy: 0.9475\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 1338s 2s/step - loss: 0.0607 - accuracy: 0.9791 - val_loss: 0.1428 - val_accuracy: 0.9471\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 1239s 2s/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 0.1547 - val_accuracy: 0.9469\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 1260s 2s/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 0.1199 - val_accuracy: 0.9579\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 1308s 2s/step - loss: 0.0313 - accuracy: 0.9889 - val_loss: 0.1235 - val_accuracy: 0.9613\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 1226s 2s/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.1639 - val_accuracy: 0.9475\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 1351s 2s/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 0.1179 - val_accuracy: 0.9621\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 1437s 2s/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 0.1298 - val_accuracy: 0.9605\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 1175s 2s/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1282 - val_accuracy: 0.9633\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 1210s 2s/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.1332 - val_accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "train_steps = 40000//batch_size\n",
    "valid_steps = 5000//batch_size\n",
    "history = cnn.fit_generator(\n",
    "    train_flow,\n",
    "    epochs=15,\n",
    "    steps_per_epoch = train_steps,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = valid_steps,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae73e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_epoch_accuracy = history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efacf6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the latest epoch: 0.9947916865348816\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the latest epoch:\", latest_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dc0dba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "test_flow = image_gen.flow_from_directory(\n",
    "    test,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a56a1628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 299s 15ms/step - loss: 0.1341 - accuracy: 0.9634\n"
     ]
    }
   ],
   "source": [
    "results = cnn.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcb5dbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import load_img, img_to_array\n",
    "test_image=load_img(r\"C:\\Users\\itars\\Downloads\\fotor_2023-5-13_16_9_28.jpg\", target_size = (224, 224))\n",
    "test_image=img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "train_flow.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'REAL'\n",
    "else:\n",
    "  prediction = 'FAKE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eebeb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71958b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
